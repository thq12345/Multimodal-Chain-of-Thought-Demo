# Multimodal-Chain-of-Thought-Demo

## Chain-of-Thought, explained in one sentence
Multimodal Chain-of-Thought refers to Model providing rationale in addition to giving answer to a question and visual.
![alt text](supporting_images/image1.png)

### Why does it matter?
It helps building explainable AI.

## What is this paper about?
The paper introduced a mini-model (less than 1B parameter) that combined textual transformer and visual transformer that provide rationale and solution to a given question that yields 20% better performance than 175B GPT 3.5 model.

Essentially, you provide the question, and an image demonstrating the problem, it will provide answer, and rationale to the answer.

## What was the status quo before this paper? What is the innovative idea here?
Chain of Thought (CoT) reason was more on language transformers, with minimal consideration for multimodal scenarios that involve both language (text) and vision (images). 

Usually model deducing rationale only happens with larger models, models smaller than 100B parameters tend to produce illogical rationale. Having a mini model that yields better performance than large models is very rare. 

## Dataset
ScienceQA

## How does the algorithm work?

### Question 1: What is model fusion?

## Demonstration/Rant
Refer to Jupyter Notebook. Conducted heavy source-code modification.
#### Rationale Generated by model:
![alt text](supporting_images/rationale_generation.png)
#### Answer Generated by model:
![alt text](supporting_images/answer_generation.png)









